{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse deskewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not find scikit-tensor which is needed for separable approximations...\n",
      "If you want to compute separable approximations, please install it with\n",
      "pip install scikit-tensor-py3\n",
      "Shape of original image (150, 118, 209)\n",
      "Shape of deskewed image (59, 416, 209)\n"
     ]
    }
   ],
   "source": [
    "from skimage.io import imread\n",
    "import napari\n",
    "import pyclesperanto_prototype as cle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "#Read lattice file\n",
    "rbc = imread(\"../sample_data/RBC_lattice.tif\")\n",
    "\n",
    "voxel_size_x_in_microns = 0.1449922\n",
    "voxel_size_y_in_microns = 0.1449922\n",
    "voxel_size_z_in_microns = 0.3\n",
    "\n",
    "deskewing_angle_in_degrees = 30\n",
    "\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(rbc)\n",
    "\n",
    "\n",
    "#Perform deskewing on rbc image  \n",
    "deskewed = cle.deskew_y(rbc, \n",
    "                        angle_in_degrees=deskewing_angle_in_degrees, \n",
    "                        voxel_size_x=voxel_size_x_in_microns, \n",
    "                        voxel_size_y=voxel_size_y_in_microns, \n",
    "                        voxel_size_z=voxel_size_z_in_microns)\n",
    "\n",
    "viewer.add_image(deskewed)\n",
    "\n",
    "print(\"Shape of original image\", rbc.shape )\n",
    "\n",
    "print(\"Shape of deskewed image\",deskewed.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reverse the deskewing transformation from deskewed volume back into the original volume\n",
    "\n",
    "Main differences with deskewing are \n",
    "* Transforms are concatenated in the reverse order, compared to `deskew_y` function\n",
    "* Shear matrix: shearing angle is negative\n",
    "* Rotation matrices: negative of shearing angle and -90 for rotation\n",
    "* Scaling matrix is inverted using np.linalg.inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'transformed_translated [1]' at 0x1824f267430>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "scaling_factor = 1\n",
    "\n",
    "#Define tranform\n",
    "transform = cle.AffineTransform3D()\n",
    "\n",
    "#Shear Transformation\n",
    "shear_mat = cle.AffineTransform3D()\n",
    "shear_mat.shear_in_x_plane(angle_y_in_degrees = -(90-deskewing_angle_in_degrees))\n",
    "transform._concatenate(shear_mat) #concatenate instead of pre_concatenate\n",
    "\n",
    "#Rotate along deskewing angle\n",
    "rotate_transform = cle.AffineTransform3D()\n",
    "rotate_transform.rotate(angle_in_degrees=-(90-deskewing_angle_in_degrees), axis=0)\n",
    "transform._pre_concatenate(rotate_transform) #pre_concatenate instead of concatenate\n",
    "\n",
    "#Invert scaling\n",
    "new_dz=math.sin(deskewing_angle_in_degrees * math.pi/180.0)*voxel_size_z_in_microns\n",
    "scale_factor_z=(new_dz/voxel_size_y_in_microns)*scaling_factor\n",
    "    \n",
    "scale_transform = cle.AffineTransform3D()\n",
    "scale_transform.scale(scale_x = scaling_factor, scale_y = scaling_factor, scale_z=scale_factor_z)\n",
    "scale_inverse = np.linalg.inv(scale_transform._matrix)\n",
    "transform._pre_concatenate(scale_inverse)  #pre_concatenate instead of concatenate\n",
    "\n",
    "#Rotate -90 degrees\n",
    "rotate_transform1 = cle.AffineTransform3D()\n",
    "rotate_transform1.rotate(angle_in_degrees=-(90), axis=0)\n",
    "transform._pre_concatenate(rotate_transform1)#pre_concatenate instead of concatenate\n",
    "\n",
    "#Perform above transformation first, which returns a deskewed volume\n",
    "transformed = cle.affine_transform(source=deskewed, transform = transform, auto_size=True)\n",
    "viewer.add_image(transformed)\n",
    "\n",
    "\n",
    "#Translate image so it stays within bounds\n",
    "\n",
    "from itertools import product\n",
    "nz, ny, nx = deskewed.shape\n",
    "original_bounding_box = [list(x) + [1] for x in product((0, nx), (0, ny), (0, nz))]\n",
    "# transform the corners using the given affine transform \n",
    "transformed_bounding_box = np.asarray(list(map(lambda x: transform._matrix@x, original_bounding_box)))\n",
    "translation = transformed_bounding_box[1][2]\n",
    "\n",
    "#Calculate translation based on bounding box corner\n",
    "transform_translate =  cle.AffineTransform3D()\n",
    "transform_translate.translate (translate_z = translation)\n",
    "\n",
    "\n",
    "#subtract opposite vertices for new shape\n",
    "new_shape = np.abs(np.rint(transformed_bounding_box[6] - transformed_bounding_box[1])).astype(int)[0:3].tolist()[::-1]\n",
    "\n",
    "#Create new shape and perform affine transformation using this as destination\n",
    "transformed_translated = cle.create(new_shape)\n",
    "\n",
    "#pass volume with new shape as destination and apply translation\n",
    "cle.affine_transform(source=transformed, destination = transformed_translated, transform = transform_translate)\n",
    "\n",
    "viewer.add_image(transformed_translated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if the shape of reverse transformed object is same as the original volume\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Checking if the shape of reverse transformed object is same as the original volume\")\n",
    "transformed_translated.shape == rbc.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00],\n",
       "       [ 0.0000e+00,  1.1800e+02, -5.1095e+01,  1.0000e+00],\n",
       "       [ 0.0000e+00,  1.7291e-13, -2.0106e+02,  1.0000e+00],\n",
       "       [ 0.0000e+00,  1.1800e+02, -2.5215e+02,  1.0000e+00],\n",
       "       [ 2.0900e+02,  0.0000e+00,  0.0000e+00,  1.0000e+00],\n",
       "       [ 2.0900e+02,  1.1800e+02, -5.1095e+01,  1.0000e+00],\n",
       "       [ 2.0900e+02,  1.7291e-13, -2.0106e+02,  1.0000e+00],\n",
       "       [ 2.0900e+02,  1.1800e+02, -2.5215e+02,  1.0000e+00]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print so np arrays have only 4 decimal places; makes it cleaner\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "transformed_bounding_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse transformation of ROI\n",
    "Add shapes layer and draw ROI on the deskewed stack.\n",
    "Run the cell after this to get bounding box in 3D\n",
    "\n",
    "`Z axes being returned after transformation are not accurate.. Need to fix that`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[47, 127, 0, 1],\n",
       " [47, 127, 58, 1],\n",
       " [47, 246, 0, 1],\n",
       " [47, 246, 58, 1],\n",
       " [179, 127, 0, 1],\n",
       " [179, 127, 58, 1],\n",
       " [179, 246, 0, 1],\n",
       " [179, 246, 58, 1]]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code to read shapes layer and get bounding box in 3D\n",
    "\n",
    "import numpy as np \n",
    "shapes_layer = viewer.layers[\"Shapes\"]\n",
    "shape_types = shapes_layer.shape_type\n",
    "shapes = shapes_layer.data\n",
    "\n",
    "\n",
    "shape = shapes[0]\n",
    "start = np.rint(np.min(shape, axis=0))\n",
    "stop = np.rint(np.max(shape, axis=0))\n",
    "\n",
    "_,y0,x0 = np.stack([start,stop])[0].astype(int)\n",
    "_,y1,x1 = np.stack([start,stop])[1].astype(int)\n",
    "\n",
    "crop_shape = (stop - start).astype(int).tolist()\n",
    "z0 = 0\n",
    "z1 = deskewed.shape[0]-1\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "crop_bounding_box = [list(x)+[1] for x in product((x0,x1),(y0,y1),(z0,z1))] \n",
    "#crop_bounding_box = [list(x)+[1] for x in product((z0,z1),(y0,y1),(x0,x1))] \n",
    "crop_bounding_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.7000e+01, -5.2788e-14,  1.1248e+02, -1.0000e+00],\n",
       "       [-4.7000e+01, -1.1600e+02,  1.6271e+02, -1.0000e+00],\n",
       "       [-4.7000e+01, -1.0225e-13,  1.6999e+02, -1.0000e+00],\n",
       "       [-4.7000e+01, -1.1600e+02,  2.2022e+02, -1.0000e+00],\n",
       "       [-1.7900e+02, -5.2788e-14,  1.1248e+02, -1.0000e+00],\n",
       "       [-1.7900e+02, -1.1600e+02,  1.6271e+02, -1.0000e+00],\n",
       "       [-1.7900e+02, -1.0225e-13,  1.6999e+02, -1.0000e+00],\n",
       "       [-1.7900e+02, -1.1600e+02,  2.2022e+02, -1.0000e+00]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reverse_transform = cle.AffineTransform3D()\n",
    "#transform_translate._pre_concatenate(transform)\n",
    "#reverse_transform._concatenate(transform_translate)\n",
    "\n",
    "#Working on using suitable transformations\n",
    "\n",
    "crop_transformed_bounding_box=np.asarray(list(map(lambda x:transform._matrix@x,crop_bounding_box)))\n",
    "crop_transformed_bounding_box1=np.asarray(list(map(lambda x:transform_translate._matrix@x,crop_transformed_bounding_box)))\n",
    "crop_transformed_bounding_box1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  47.    0. -169. 3137.]\n",
      "[ 179.  116.  -61. 8642.]\n"
     ]
    }
   ],
   "source": [
    "slice0 = np.rint(np.min(crop_transformed_bounding_box1,axis=0))\n",
    "slice1= np.rint(np.max(crop_transformed_bounding_box1,axis=0))\n",
    "print(slice0)\n",
    "print(slice1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test function for returning only the transform for deskewing.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyclesperanto_prototype as cle\n",
    "from pyclesperanto_prototype import Image, affine_transform, AffineTransform3D\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import product\n",
    "\n",
    "#GEt transformation for deskewing\n",
    "def deskew_y_transform(input_image ,\n",
    "             angle_in_degrees: float = 30,\n",
    "             voxel_size_x: float = 1,\n",
    "             voxel_size_y: float = 1,\n",
    "             voxel_size_z: float = 1,\n",
    "             scaling_factor: float = 1\n",
    "             ):\n",
    "    #Return only the affine transform\n",
    "\n",
    "    # shear in the X plane towards Y\n",
    "    transform = AffineTransform3D()\n",
    "    transform.shear_in_x_plane(angle_y_in_degrees = 90 - angle_in_degrees)\n",
    "\n",
    "    # rotate the stack to get proper Z-planes; rotate 90 - angle around X-axis\n",
    "    transform.rotate(angle_in_degrees = 90-angle_in_degrees, axis=0)\n",
    "\n",
    "    # make voxels isotropic, calculate the new scaling factor for Z after shearing\n",
    "    #https://github.com/tlambert03/napari-ndtiffs/blob/092acbd92bfdbf3ecb1eb9c7fc146411ad9e6aae/napari_ndtiffs/affine.py#L57\n",
    "    new_dz=math.sin(angle_in_degrees * math.pi/180.0)*voxel_size_z\n",
    "    scale_factor_z=(new_dz/voxel_size_y)*scaling_factor\n",
    "    transform.scale(scale_x = scaling_factor, scale_y = scaling_factor, scale_z=scale_factor_z)\n",
    "\n",
    "    # correct orientation so that the new Z-plane goes proximal-distal from the objective.\n",
    "    transform.rotate(angle_in_degrees=90, axis=0)\n",
    "\n",
    "    #Calculate new affine transform \n",
    "    new_shape, new_affine_transform, translation = cle._tier8._affine_transform._determine_translation_and_bounding_box(input_image, transform)\n",
    "\n",
    "    #Return the affine transform and the translation\n",
    "    return new_affine_transform, translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'Image [1]' at 0x20f955fd340>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(rbc[0:63,0:118,102:142])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49, 45]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_shape = (stop - start).astype(int).tolist()\n",
    "crop_shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "10b99887b74cc4cb4bd2264f3862ab915c02278d8edd73c34b702f5c5ffd1029"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('napari-lattice': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
