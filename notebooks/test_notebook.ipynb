{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RedLionfishDeconv as RL\n",
    "from skimage.io import imread ,imsave\n",
    "psf_path = \"C:\\\\Users\\\\Pradeep\\\\Downloads\\\\PSF_RFI_8bit.tif\"\n",
    "img_path = \"C:\\\\Users\\\\Pradeep\\\\Downloads\\\\gendata_psfconv_poiss_large.tif\"\n",
    "\n",
    "img = imread(img_path)\n",
    "psf = imread(psf_path)\n",
    "\n",
    "final = RL.doRLDeconvolutionFromNpArrays(data_np = img,psf_np = psf,method='gpu',useBlockAlgorithm=True)\n",
    "imsave(\"D:\\\\decon_block.tif\",final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Shape (60, 1026, 1544) is too large for OpenCL device shape limits [1024, 1024, 64]\n"
     ]
    }
   ],
   "source": [
    "final2 = RL.doRLDeconvolutionFromNpArrays(data_np = img,psf_np = psf,method='gpu',useBlockAlgorithm=False)\n",
    "imsave(\"D:\\\\decon_no_block.tif\",final2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get deskewing data and try it as a workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow:\n",
      "deskewing <- (<function deskew_y at 0x000001A8DFECE1F0>, 'input', None, 30, 0.145, 0.145, 0.3, 1)\n",
      "median <- (<function median_sphere at 0x000001A8DFD8E160>, 'deskewing', None, 2, 2, 2)\n",
      "binarisation <- (<function greater_constant at 0x000001A8DFD725E0>, 'median', None, 1000)\n",
      "labeling <- (<function connected_components_labeling_box at 0x000001A8DFE285E0>, 'binarisation')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from napari_workflows import Workflow\n",
    "import pyclesperanto_prototype as cle\n",
    "image_seg_workflow = Workflow()\n",
    "from skimage.io import imread\n",
    "\n",
    "img = imread(\"C:\\\\Users\\\\deepu\\\\Desktop\\\\RBC_lattice_anisotropic.tif\")\n",
    "\n",
    "voxel_size_x_in_microns = 0.145\n",
    "voxel_size_y_in_microns = 0.145\n",
    "voxel_size_z_in_microns = 0.3\n",
    "deskewing_angle_in_degrees = 30\n",
    "\n",
    "input_arg = \"input\"\n",
    "image_seg_workflow.set(\"deskewing\", cle.deskew_y, input_arg, angle_in_degrees = deskewing_angle_in_degrees,\n",
    "                    voxel_size_x = voxel_size_x_in_microns, voxel_size_y= voxel_size_y_in_microns,\n",
    "                    voxel_size_z = voxel_size_z_in_microns)\n",
    "\n",
    "image_seg_workflow.set(\"median\", cle.median_sphere,\"deskewing\",radius_x = 2, radius_y = 2, radius_z = 2)\n",
    "\n",
    "image_seg_workflow.set(\"binarisation\", cle.threshold,\"median\",constant =1000)\n",
    "\n",
    "image_seg_workflow.set(\"labeling\", cle.connected_components_labeling_box,\"binarisation\")\n",
    "\n",
    "print(str(image_seg_workflow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Viewer' from 'napari' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\OneDrive - wehi.edu.au\\WEHI_projects\\Lightsheet\\LLSZ_repo\\llsz_napari\\notebooks\\test_notebook.ipynb Cell 6'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20wehi.edu.au/WEHI_projects/Lightsheet/LLSZ_repo/llsz_napari/notebooks/test_notebook.ipynb#ch0000016?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnapari_workflows\u001b[39;00m \u001b[39mimport\u001b[39;00m Workflow\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20wehi.edu.au/WEHI_projects/Lightsheet/LLSZ_repo/llsz_napari/notebooks/test_notebook.ipynb#ch0000016?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnapari_workflows\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_io_yaml_v1\u001b[39;00m \u001b[39mimport\u001b[39;00m load_workflow, save_workflow\n",
      "File \u001b[1;32mc:\\Users\\Pradeep\\.conda\\envs\\llsz\\lib\\site-packages\\napari_workflows\\__init__.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='file:///c%3A/Users/Pradeep/.conda/envs/llsz/lib/site-packages/napari_workflows/__init__.py?line=1'>2</a>\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.1.5\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='file:///c%3A/Users/Pradeep/.conda/envs/llsz/lib/site-packages/napari_workflows/__init__.py?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_workflow\u001b[39;00m \u001b[39mimport\u001b[39;00m Workflow\n\u001b[0;32m      <a href='file:///c%3A/Users/Pradeep/.conda/envs/llsz/lib/site-packages/napari_workflows/__init__.py?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_workflow\u001b[39;00m \u001b[39mimport\u001b[39;00m WorkflowManager\n",
      "File \u001b[1;32mc:\\Users\\Pradeep\\.conda\\envs\\llsz\\lib\\site-packages\\napari_workflows\\_workflow.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='file:///c%3A/Users/Pradeep/.conda/envs/llsz/lib/site-packages/napari_workflows/_workflow.py?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnapari\u001b[39;00m\n\u001b[1;32m----> <a href='file:///c%3A/Users/Pradeep/.conda/envs/llsz/lib/site-packages/napari_workflows/_workflow.py?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnapari\u001b[39;00m \u001b[39mimport\u001b[39;00m Viewer\n\u001b[0;32m      <a href='file:///c%3A/Users/Pradeep/.conda/envs/llsz/lib/site-packages/napari_workflows/_workflow.py?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='file:///c%3A/Users/Pradeep/.conda/envs/llsz/lib/site-packages/napari_workflows/_workflow.py?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39minspect\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Viewer' from 'napari' (unknown location)"
     ]
    }
   ],
   "source": [
    "from napari_workflows import Workflow\n",
    "from napari_workflows._io_yaml_v1 import load_workflow, save_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function deskew_y at 0x000001A8DFECE1F0>\n",
      "<function median_sphere at 0x000001A8DFD8E160>\n",
      "<function greater_constant at 0x000001A8DFD725E0>\n",
      "<function connected_components_labeling_box at 0x000001A8DFE285E0>\n"
     ]
    }
   ],
   "source": [
    "for key in image_seg_workflow._tasks.keys():\n",
    "    for task in image_seg_workflow._tasks[key]:\n",
    "        if hasattr(task, '__call__'): # if function\n",
    "            print(task)\n",
    "            #validate_task_install(task)\n",
    "            #print(task.__module__)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original image (150, 118, 209)\n"
     ]
    }
   ],
   "source": [
    "import pyclesperanto_prototype as cle\n",
    "from skimage.io import imread\n",
    "\n",
    "img = imread(\"../sample_data/RBC_lattice.tif\")\n",
    "\n",
    "voxel_size_x_in_microns = 0.1449922\n",
    "voxel_size_y_in_microns = 0.1449922\n",
    "voxel_size_z_in_microns = 0.3\n",
    "\n",
    "deskewing_angle_in_degrees = 30\n",
    "\n",
    "print(\"Shape of original image\", img.shape )\n",
    "\n",
    "#Perform deskewing on rbc image  \n",
    "deskewed = cle.deskew_y(img, \n",
    "                        angle_in_degrees=deskewing_angle_in_degrees, \n",
    "                        voxel_size_x=voxel_size_x_in_microns, \n",
    "                        voxel_size_y=voxel_size_y_in_microns, \n",
    "                        voxel_size_z=voxel_size_z_in_microns)\n",
    "\n",
    "print(\"Shape of deskewed image\",deskewed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of deskewed image (59, 413, 209)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deepu\\Anaconda3\\envs\\napari_lattice\\lib\\site-packages\\napari_tools_menu\\__init__.py:194: FutureWarning: Public access to Window.qt_viewer is deprecated and will be removed in\n",
      "v0.5.0. It is considered an \"implementation detail\" of the napari\n",
      "application, not part of the napari viewer model. If your use case\n",
      "requires access to qt_viewer, please open an issue to discuss.\n",
      "  self.tools_menu = ToolsMenu(self, self.qt_viewer.viewer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Image layer 'deskewed' at 0x270362f9820>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit, prange\n",
    "import numpy as np\n",
    "\n",
    "@njit(parallel=True)\n",
    "def opm_deskew(data,theta,distance,pixel_size):\n",
    "    \"\"\"\n",
    "    Perform parallelized orthogonal interpolation into a uniform pixel size grid.\n",
    "    \n",
    "    :param data: ndarray\n",
    "        image stack of uniformly spaced OPM planes\n",
    "    :param theta: float \n",
    "        angle relative to coverslip\n",
    "    :param distance: float \n",
    "        step between image planes along coverslip\n",
    "    :param pizel_size: float \n",
    "        in-plane camera pixel size in OPM coordinates\n",
    "    :return output: ndarray\n",
    "        image stack of deskewed OPM planes on uniform grid\n",
    "    \"\"\"\n",
    "\n",
    "    # unwrap parameters \n",
    "    [num_images,ny,nx]=data.shape     # (pixels)\n",
    "\n",
    "    # change step size from physical space (nm) to camera space (pixels)\n",
    "    pixel_step = distance/pixel_size    # (pixels)\n",
    "\n",
    "    # calculate the number of pixels scanned during stage scan \n",
    "    scan_end = num_images * pixel_step  # (pixels)\n",
    "\n",
    "    # calculate properties for final image\n",
    "    final_ny = np.int64(np.ceil(scan_end+ny*np.cos(theta*np.pi/180))) # (pixels)\n",
    "    final_nz = np.int64(np.ceil(ny*np.sin(theta*np.pi/180)))          # (pixels)\n",
    "    final_nx = np.int64(nx)                                           # (pixels)\n",
    "\n",
    "    # create final image\n",
    "    output = np.zeros((final_nz, final_ny, final_nx),dtype=np.float32)  # (time, pixels,pixels,pixels - data is float32)\n",
    "\n",
    "    # precalculate trig functions for scan angle\n",
    "    tantheta = np.float32(np.tan(theta * np.pi/180)) # (float32)\n",
    "    sintheta = np.float32(np.sin(theta * np.pi/180)) # (float32)\n",
    "    costheta = np.float32(np.cos(theta * np.pi/180)) # (float32)\n",
    "\n",
    "    # perform orthogonal interpolation\n",
    "\n",
    "    # loop through output z planes\n",
    "    # defined as parallel loop in numba\n",
    "    # http://numba.pydata.org/numba-doc/latest/user/parallel.html#numba-parallel\n",
    "    for z in prange(0,final_nz):\n",
    "        # calculate range of output y pixels to populate\n",
    "        y_range_min=np.minimum(0,np.int64(np.floor(np.float32(z)/tantheta)))\n",
    "        y_range_max=np.maximum(final_ny,np.int64(np.ceil(scan_end+np.float32(z)/tantheta+1)))\n",
    "\n",
    "        # loop through final y pixels\n",
    "        # defined as parallel loop in numba\n",
    "        # http://numba.pydata.org/numba-doc/latest/user/parallel.html#numba-parallel\n",
    "        for y in prange(y_range_min,y_range_max):\n",
    "\n",
    "            # find the virtual tilted plane that intersects the interpolated plane \n",
    "            virtual_plane = y - z/tantheta\n",
    "\n",
    "            # find raw data planes that surround the virtual plane\n",
    "            plane_before = np.int64(np.floor(virtual_plane/pixel_step))\n",
    "            plane_after = np.int64(plane_before+1)\n",
    "\n",
    "            # continue if raw data planes are within the data range\n",
    "            if ((plane_before>=0) and (plane_after<num_images)):\n",
    "                \n",
    "                # find distance of a point on the  interpolated plane to plane_before and plane_after\n",
    "                l_before = virtual_plane - plane_before * pixel_step\n",
    "                l_after = pixel_step - l_before\n",
    "                \n",
    "                # determine location of a point along the interpolated plane\n",
    "                za = z/sintheta\n",
    "                virtual_pos_before = za + l_before*costheta\n",
    "                virtual_pos_after = za - l_after*costheta\n",
    "\n",
    "                # determine nearest data points to interpoloated point in raw data\n",
    "                pos_before = np.int64(np.floor(virtual_pos_before))\n",
    "                pos_after = np.int64(np.floor(virtual_pos_after))\n",
    "\n",
    "                # continue if within data bounds\n",
    "                if ((pos_before>=0) and (pos_after >= 0) and (pos_before<ny-1) and (pos_after<ny-1)):\n",
    "                    \n",
    "                    # determine points surrounding interpolated point on the virtual plane \n",
    "                    dz_before = virtual_pos_before - pos_before\n",
    "                    dz_after = virtual_pos_after - pos_after\n",
    "\n",
    "                    # compute final image plane using orthogonal interpolation\n",
    "                    output[z,y,:] = (l_before * dz_after * data[plane_after,pos_after+1,:] +\n",
    "                                    l_before * (1-dz_after) * data[plane_after,pos_after,:] +\n",
    "                                    l_after * dz_before * data[plane_before,pos_before+1,:] +\n",
    "                                    l_after * (1-dz_before) * data[plane_before,pos_before,:]) /pixel_step\n",
    "\n",
    "\n",
    "    # return output\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "deskew_opm = opm_deskew(img,30.0,0.3,0.1449922)\n",
    "deskew_opm = np.flip(deskew_opm,axis=0) #coverslip rotation\n",
    "\n",
    "print(deskew)\n",
    "\n",
    "import napari \n",
    "\n",
    "viewer = napari.Viewer() \n",
    "\n",
    "viewer.add_image(img)\n",
    "viewer.add_image(deskewed)\n",
    "viewer.add_image(deskew_opm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deepu\\Anaconda3\\envs\\napari_lattice\\lib\\site-packages\\napari_tools_menu\\__init__.py:194: FutureWarning: Public access to Window.qt_viewer is deprecated and will be removed in\n",
      "v0.5.0. It is considered an \"implementation detail\" of the napari\n",
      "application, not part of the napari viewer model. If your use case\n",
      "requires access to qt_viewer, please open an issue to discuss.\n",
      "  self.tools_menu = ToolsMenu(self, self.qt_viewer.viewer)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Image layer 'deskew_opm' at 0x270427f7790>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deepu\\Anaconda3\\envs\\napari_lattice\\lib\\site-packages\\napari\\layers\\image\\image.py:839: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  raw_zoom_factor = np.divide(\n",
      "c:\\Users\\deepu\\Anaconda3\\envs\\napari_lattice\\lib\\site-packages\\napari\\layers\\image\\image.py:847: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  zoom_factor = tuple(new_shape / image.shape[:2])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('napari_lattice')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1bca88ceff35d1c24cb5693b49134c52beacd17ba07b354dffd5545cda12a9f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
